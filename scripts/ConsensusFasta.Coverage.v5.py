"""
Now that the readreport script has been fixed - this code does two things (
    to see changes that were made see ConsensusFasta.Coverage.v3.py):


1. Generates a consensus sequence for individual samples as well as concatenated samples.
- Individual samples have all segments in one fasta
- Otherwise it is by segment and full genome
-If coverage is below provided cutoff, the nt will be replaced with an "N"

2. Pulls coverage information- that can then be used for coverage figures, etc

NOTE: You will need to specify where to save files - I recommend making separate coverage and consensus directories

TO RUN:
python3 ConsensusFasta.Coverage.v5.py --ref ../MergedRuns/reference/SARS-COV-2.fasta --var ../MergedRuns/NYU/fullvarlist/ --strain cov19 --savecov ../MergedRuns/NYU/coverage --savecon ../MergedRuns/NYU/consensus

INPUTS:
ref: reference sequence to iterate through (for flu it iterates through segments, make sure to indicate path as well to reference fasta)
var: where the snplist files (generated by the readreport script) are located
cov: the coverage cutoff that you prefer to call a 'major' nt (default is 10)
strain: the strain of the sample, or an id for the samples.
        THIS IS USED FOR NAMING OF SAMPLES - AND IS BASED OFF OF MY ALIGNMENT AND
        VARIANT CALLING PIPELINE SCRIPTS. TO DETERMINE WHAT THIS MAY BE -
        LOOK AT THE NAME OF THE SNPLIST FILES:

        *STRAIN.SEGMENT.0.01.snplist.csv

        The readreport script will make the strain in caps! As will this script
savecov: where to save the coverage files (default .)- directory path (no / at the end)
savecon: where to save the consensus files (default .) - directory path (no / at the end)

OUTPUTS:
Consensus fasta files
Coverage file for all samples of a strain

"""
import os
import glob
import pandas as pd
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--ref','-r',required=True,help='Indicate path and reference fasta file') #args.ref
parser.add_argument('--var','-v',required=True,help='Indicate path to variant files') #args.ref
parser.add_argument('--cov','-c', default=10, help='indicate coverage cutoff threshold') #args.ref
parser.add_argument('--strain','-s',required=True,help='Indicate strain') #args.ref
parser.add_argument('--savecov',default = '.', help='Indicate directory to save coverage csv') #args.ref
parser.add_argument('--savecon',default = '.', help='Indicate directory to save coverage csv') #args.ref
parser.add_argument('--freqcut','-q', default=0.01, help='Indicate frequency cutoff')
args = parser.parse_args()

def read_fasta(fp): #function to read each segment of fasta, from tim readreport
    name, seq = None, []
    for line in fp:
        line = line.rstrip()
        if line.startswith(">"):
            if name: yield (name, ''.join(seq))
            name, seq = line, []
        else:
            seq.append(line)
    if name: yield (name, ''.join(seq))

def open_fasta(filename): #opens each fasta- makes a dictionary of segment name from tim readreport
    # filename = '../FILES/reference/'+someref
    segdict = {}
    with open(filename) as fp:
        for name, seq in read_fasta(fp):
            segdict[name[1:]] = seq
    return segdict

def add_row(df,ntpos_list,segment,name):
    """
    INPUT: Dataframe, and positions that differ from ref
    OUTPUT: Updated dataframe, with positions that were originally missing
    """
    for ntpos in ntpos_list: #iterate through list
        #generate new row of data
        new_row = {'name':name,'segment':segment,'ntpos':ntpos,'major':"N",'majorfreq':0,'minor':"",'minorfreq':"",'binocheck':"",'A':0,'C':0,'G':0,'T':0,'-':0,'totalcount':0,'aapos':"",'majoraa':"",'majorcodon':"",'minoraa':"",'minorcodon':""}
        #append to dataframe
        df = df.append(new_row,ignore_index=True)

    return df #return updated dataframe


#########################################################################################################################
ref = args.ref
path = args.var
STRAIN = args.strain.upper()
COVERAGE_CUTOFF = int(args.cov)#10 #the lowest coverage that you will allow - this is usually acceptable for the major nucleotide
refdict = open_fasta(ref)
minfreq = args.freqcut

cdf = pd.DataFrame()

for SEGMENT in refdict:
    print(SEGMENT)

    poor_alignments = []

    outf = open('{3}/{0}.{1}.{2}.fasta'.format(SEGMENT,COVERAGE_CUTOFF,STRAIN,args.savecon), 'w') # open segment fasta

    outf.write('>' + SEGMENT + '\n' + refdict[SEGMENT] + '\n') # write the reference sequence to segment fasta

    seg_len = len(refdict[SEGMENT]) # length of segments

    print(seg_len)

    #generate list so we pull positions that are within this range
    seg_list = list(range(1, seg_len + 1))

    for infile in glob.glob( os.path.join(path, '*{0}.{1}*{2}.snplist.csv'.format(STRAIN.upper(),SEGMENT, minfreq)) ):#will go through each specified csv file
        #print(infile)
        filename = str(infile)  # pull file name to get sample name for naming fasta sequences

        filename_split = filename.split(SEGMENT)  # split up the filename to grab only the name

        df = pd.read_csv(infile, keep_default_na=False)  # pandas will read the csv file create dataframe

        name = list(set(df['name']))[0] #pull name of sample

        #print(name)

        fullname = '{0}_{1}'.format(name, SEGMENT)  # name of sequence for fasta file

        ntpos_list = list(df['ntpos'])  # pull nt pos from snplist file

        differ = list(set(seg_list) - set(ntpos_list))  # determine if there are regions missing


        if len(differ) != 0 :
            print(sorted(differ))

            poor_alignments.append("{0}-{1}".format(name,SEGMENT))  # provide all the samples that need a new file - still append to double check that readreport worked!

        else:
            #continue
            # if the lengths don't differ then make information for it

            covdf = df[['name','segment','ntpos','totalcount']]

            cdf = cdf.append(covdf)

            #generate consensus
            df[['totalcount']] = df[['totalcount']].apply(pd.to_numeric) #make total count numeric to compare

            #change any low coverage positions to 'N'
            df.loc[df.totalcount < COVERAGE_CUTOFF, "major"] = 'N'

            #generate consensus seq by pulling column in sorted,reindexed df
            consensus_seq = "".join(list(df['major']))

            #print(len(consensus_seq))

            # output individual files
            outi = open('{3}/{0}.{1}.{2}.{4}.fasta'.format(name,COVERAGE_CUTOFF,STRAIN,args.savecon,SEGMENT), 'w')

            outi.write('>' + name + '\n' + consensus_seq + '\n')

            outi.close()

            #write to fasta file - with all samples segment information
            outf.write('>' + fullname + '\n' + consensus_seq + '\n')

            #print(SEGMENT)

    outf.close() #close fasta file (by segment)

print(poor_alignments)

cdf.to_csv("{0}/{1}.coverage.csv".format(args.savecov,STRAIN.upper()),index=False) # ALL COVERAGE INFORMATION - ALL SEGMENTS
